Guest DBMS identified: postgres
-----------
QUERY:
-- When there is a LIMIT clause, incremental sort is beneficial because
-- it only has to sort some of the groups, and not the entire table.
explain (costs off)
select * from (select * from tenk1 order by four) t order by four, ten
limit 1;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


-- When work_mem is not enough to sort the entire table, incremental sort
-- may be faster if individual groups still fit into work_mem.
set work_mem to '2MB';
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

explain (costs off)
select * from (select * from tenk1 order by four) t order by four, ten;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

reset work_mem;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


create table t(a integer, b integer);
RESULT: [duckdb: SAME, mysql: SAME]

-----------
QUERY:


create or replace function explain_analyze_without_memory(query text)
returns table (out_line text) language plpgsql
as
$$
declare
  line text;
begin
  for line in
    execute 'explain (analyze, costs off, summary off, timing off) ' || query
  loop
    out_line := regexp_replace(line, '\d+kB', 'NNkB', 'g');
    return next;
  end loop;
end;
$$;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


create or replace function explain_analyze_inc_sort_nodes(query text)
returns jsonb language plpgsql
as
$$
declare
  elements jsonb;
  element jsonb;
  matching_nodes jsonb := '[]'::jsonb;
begin
  execute 'explain (analyze, costs off, summary off, timing off, format ''json'') ' || query into strict elements;
  while jsonb_array_length(elements) > 0 loop
    element := elements->0;
    elements := elements - 0;
    case jsonb_typeof(element)
    when 'array' then
      if jsonb_array_length(element) > 0 then
        elements := elements || element;
      end if;
    when 'object' then
      if element ? 'Plan' then
        elements := elements || jsonb_build_array(element->'Plan');
        element := element - 'Plan';
      else
        if element ? 'Plans' then
          elements := elements || jsonb_build_array(element->'Plans');
          element := element - 'Plans';
        end if;
        if (element->>'Node Type')::text = 'Incremental Sort' then
          matching_nodes := matching_nodes || element;
        end if;
      end if;
    end case;
  end loop;
  return matching_nodes;
end;
$$;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


create or replace function explain_analyze_inc_sort_nodes_without_memory(query text)
returns jsonb language plpgsql
as
$$
declare
  nodes jsonb := '[]'::jsonb;
  node jsonb;
  group_key text;
  space_key text;
begin
  for node in select * from jsonb_array_elements(explain_analyze_inc_sort_nodes(query)) t loop
    for group_key in select unnest(array['Full-sort Groups', 'Pre-sorted Groups']::text[]) t loop
      for space_key in select unnest(array['Sort Space Memory', 'Sort Space Disk']::text[]) t loop
        node := jsonb_set(node, array[group_key, space_key, 'Average Sort Space Used'], '"NN"', false);
        node := jsonb_set(node, array[group_key, space_key, 'Peak Sort Space Used'], '"NN"', false);
      end loop;
    end loop;
    nodes := nodes || node;
  end loop;
  return nodes;
end;
$$;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


create or replace function explain_analyze_inc_sort_nodes_verify_invariants(query text)
returns bool language plpgsql
as
$$
declare
  node jsonb;
  group_stats jsonb;
  group_key text;
  space_key text;
begin
  for node in select * from jsonb_array_elements(explain_analyze_inc_sort_nodes(query)) t loop
    for group_key in select unnest(array['Full-sort Groups', 'Pre-sorted Groups']::text[]) t loop
      group_stats := node->group_key;
      for space_key in select unnest(array['Sort Space Memory', 'Sort Space Disk']::text[]) t loop
        if (group_stats->space_key->'Peak Sort Space Used')::bigint < (group_stats->space_key->'Peak Sort Space Used')::bigint then
          raise exception '% has invalid max space < average space', group_key;
        end if;
      end loop;
    end loop;
  end loop;
  return true;
end;
$$;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


-- A single large group tested around each mode transition point.
insert into t(a, b) select i/100 + 1, i + 1 from generate_series(0, 999) n(i);
RESULT: [duckdb: SAME, mysql: ERROR]

-----------
QUERY:

analyze t;
RESULT: [duckdb: SAME, mysql: ERROR]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 31;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 31;
RESULT: [duckdb: SAME, mysql: DIFFERENT]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 32;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 32;
RESULT: [duckdb: SAME, mysql: DIFFERENT]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 33;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 33;
RESULT: [duckdb: SAME, mysql: DIFFERENT]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 65;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 65;
RESULT: [duckdb: DIFFERENT, mysql: DIFFERENT]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 66;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 66;
RESULT: [duckdb: DIFFERENT, mysql: DIFFERENT]

-----------
QUERY:

delete from t;
RESULT: [duckdb: SAME, mysql: SAME]

-----------
QUERY:


-- An initial large group followed by a small group.
insert into t(a, b) select i/50 + 1, i + 1 from generate_series(0, 999) n(i);
RESULT: [duckdb: SAME, mysql: ERROR]

-----------
QUERY:

analyze t;
RESULT: [duckdb: SAME, mysql: ERROR]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 55;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 55;
RESULT: [duckdb: DIFFERENT, mysql: DIFFERENT]

-----------
QUERY:

-- Test EXPLAIN ANALYZE with only a fullsort group.
select explain_analyze_without_memory('select * from (select * from t order by a) s order by a, b limit 55');
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select jsonb_pretty(explain_analyze_inc_sort_nodes_without_memory('select * from (select * from t order by a) s order by a, b limit 55'));
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select explain_analyze_inc_sort_nodes_verify_invariants('select * from (select * from t order by a) s order by a, b limit 55');
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

delete from t;
RESULT: [duckdb: SAME, mysql: SAME]

-----------
QUERY:


-- An initial small group followed by a large group.
insert into t(a, b) select (case when i < 5 then i else 9 end), i from generate_series(1, 1000) n(i);
RESULT: [duckdb: SAME, mysql: ERROR]

-----------
QUERY:

analyze t;
RESULT: [duckdb: SAME, mysql: ERROR]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 70;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 70;
RESULT: [duckdb: SAME, mysql: DIFFERENT]

-----------
QUERY:

-- Checks case where we hit a group boundary at the last tuple of a batch.
-- Because the full sort state is bounded, we scan 64 tuples (the mode
-- transition point) but only retain 5. Thus when we transition modes, all
-- tuples in the full sort state have different prefix keys.
explain (costs off) select * from (select * from t order by a) s order by a, b limit 5;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 5;
RESULT: [duckdb: SAME, mysql: DIFFERENT]

-----------
QUERY:


-- Test rescan.
begin;
RESULT: [duckdb: SAME, mysql: SAME]

-----------
QUERY:

-- We force the planner to choose a plan with incremental sort on the right side
-- of a nested loop join node. That way we trigger the rescan code path.
set local enable_hashjoin = off;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

set local enable_mergejoin = off;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

set local enable_material = off;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

set local enable_sort = off;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

explain (costs off) select * from t left join (select * from (select * from t order by a) v order by a, b) s on s.a = t.a where t.a in (1, 2);
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from t left join (select * from (select * from t order by a) v order by a, b) s on s.a = t.a where t.a in (1, 2);
RESULT: [duckdb: SAME, mysql: DIFFERENT]

-----------
QUERY:

rollback;
RESULT: [duckdb: SAME, mysql: SAME]

-----------
QUERY:

-- Test EXPLAIN ANALYZE with both fullsort and presorted groups.
select explain_analyze_without_memory('select * from (select * from t order by a) s order by a, b limit 70');
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select jsonb_pretty(explain_analyze_inc_sort_nodes_without_memory('select * from (select * from t order by a) s order by a, b limit 70'));
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select explain_analyze_inc_sort_nodes_verify_invariants('select * from (select * from t order by a) s order by a, b limit 70');
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

delete from t;
RESULT: [duckdb: SAME, mysql: SAME]

-----------
QUERY:


-- Small groups of 10 tuples each tested around each mode transition point.
insert into t(a, b) select i / 10, i from generate_series(1, 1000) n(i);
RESULT: [duckdb: SAME, mysql: ERROR]

-----------
QUERY:

analyze t;
RESULT: [duckdb: SAME, mysql: ERROR]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 31;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 31;
RESULT: [duckdb: DIFFERENT, mysql: DIFFERENT]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 32;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 32;
RESULT: [duckdb: DIFFERENT, mysql: DIFFERENT]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 33;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 33;
RESULT: [duckdb: DIFFERENT, mysql: DIFFERENT]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 65;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 65;
RESULT: [duckdb: DIFFERENT, mysql: DIFFERENT]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 66;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 66;
RESULT: [duckdb: DIFFERENT, mysql: DIFFERENT]

-----------
QUERY:

delete from t;
RESULT: [duckdb: SAME, mysql: SAME]

-----------
QUERY:


-- Small groups of only 1 tuple each tested around each mode transition point.
insert into t(a, b) select i, i from generate_series(1, 1000) n(i);
RESULT: [duckdb: SAME, mysql: ERROR]

-----------
QUERY:

analyze t;
RESULT: [duckdb: SAME, mysql: ERROR]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 31;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 31;
RESULT: [duckdb: SAME, mysql: DIFFERENT]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 32;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 32;
RESULT: [duckdb: SAME, mysql: DIFFERENT]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 33;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 33;
RESULT: [duckdb: SAME, mysql: DIFFERENT]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 65;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 65;
RESULT: [duckdb: SAME, mysql: DIFFERENT]

-----------
QUERY:

explain (costs off) select * from (select * from t order by a) s order by a, b limit 66;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

select * from (select * from t order by a) s order by a, b limit 66;
RESULT: [duckdb: SAME, mysql: DIFFERENT]

-----------
QUERY:

delete from t;
RESULT: [duckdb: SAME, mysql: SAME]

-----------
QUERY:


drop table t;
RESULT: [duckdb: SAME, mysql: SAME]

-----------
QUERY:


-- Incremental sort vs. parallel queries
set min_parallel_table_scan_size = '1kB';
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

set min_parallel_index_scan_size = '1kB';
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

set parallel_setup_cost = 0;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

set parallel_tuple_cost = 0;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

set max_parallel_workers_per_gather = 2;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


create table t (a int, b int, c int);
RESULT: [duckdb: SAME, mysql: SAME]

-----------
QUERY:

insert into t select mod(i,10),mod(i,10),i from generate_series(1,10000) s(i);
RESULT: [duckdb: SAME, mysql: ERROR]

-----------
QUERY:

create index on t (a);
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

analyze t;
RESULT: [duckdb: SAME, mysql: ERROR]

-----------
QUERY:


set enable_incremental_sort = off;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

explain (costs off) select a,b,sum(c) from t group by 1,2 order by 1,2,3 limit 1;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


set enable_incremental_sort = on;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

explain (costs off) select a,b,sum(c) from t group by 1,2 order by 1,2,3 limit 1;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


-- Incremental sort vs. set operations with varno 0
set enable_hashagg to off;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

explain (costs off) select * from t union select * from t order by 1,3;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


-- Full sort, not just incremental sort can be pushed below a gather merge path
-- by generate_useful_gather_paths.
explain (costs off) select distinct a,b from t;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


drop table t;
RESULT: [duckdb: SAME, mysql: SAME]

-----------
QUERY:


-- Sort pushdown can/* REPLACED */ ''t go below where expressions are part of the rel target.
-- In particular this is interesting for volatile expressions which have to
-- go above joins since otherwise we/* REPLACED */ ''ll incorrectly use expression evaluations
-- across multiple rows.
set enable_hashagg=off;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

set enable_seqscan=off;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

set enable_incremental_sort = off;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

set parallel_tuple_cost=0;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

set parallel_setup_cost=0;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

set min_parallel_table_scan_size = 0;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

set min_parallel_index_scan_size = 0;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


-- Parallel sort below join.
explain (costs off) select distinct sub.unique1, stringu1
from tenk1, lateral (select tenk1.unique1 from generate_series(1, 1000)) as sub;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

explain (costs off) select sub.unique1, stringu1
from tenk1, lateral (select tenk1.unique1 from generate_series(1, 1000)) as sub
order by 1, 2;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

-- Parallel sort but with expression that can be safely generated at the base rel.
explain (costs off) select distinct sub.unique1, md5(stringu1)
from tenk1, lateral (select tenk1.unique1 from generate_series(1, 1000)) as sub;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

explain (costs off) select sub.unique1, md5(stringu1)
from tenk1, lateral (select tenk1.unique1 from generate_series(1, 1000)) as sub
order by 1, 2;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

-- Parallel sort with an aggregate that can be safely generated in parallel,
-- but we can/* REPLACED */ ''t sort by partial aggregate values.
explain (costs off) select count(*)
from tenk1 t1
join tenk1 t2 on t1.unique1 = t2.unique2
join tenk1 t3 on t2.unique1 = t3.unique1
order by count(*);
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

-- Parallel sort but with expression (correlated subquery) that
-- is prohibited in parallel plans.
explain (costs off) select distinct
  unique1,
  (select t.unique1 from tenk1 where tenk1.unique1 = t.unique1)
from tenk1 t, generate_series(1, 1000);
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

explain (costs off) select
  unique1,
  (select t.unique1 from tenk1 where tenk1.unique1 = t.unique1)
from tenk1 t, generate_series(1, 1000)
order by 1, 2;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

-- Parallel sort but with expression not available until the upper rel.
explain (costs off) select distinct sub.unique1, stringu1 || random()::text
from tenk1, lateral (select tenk1.unique1 from generate_series(1, 1000)) as sub;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

explain (costs off) select sub.unique1, stringu1 || random()::text
from tenk1, lateral (select tenk1.unique1 from generate_series(1, 1000)) as sub
order by 1, 2;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


reset enable_hashagg;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

reset enable_seqscan;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

reset enable_incremental_sort;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

reset parallel_tuple_cost;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

reset parallel_setup_cost;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

reset min_parallel_table_scan_size;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

reset min_parallel_index_scan_size;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


-- Ensure incremental sorts work for amcanorderbyop type indexes
create table point_table (a point, b int);
RESULT: [duckdb: ERROR, mysql: SAME]

-----------
QUERY:

create index point_table_a_idx on point_table using gist(a);
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:


-- Ensure we get an incremental sort plan for both of the following queries
explain (costs off) select a, b, a <-> point(5, 5) dist from point_table order by dist, b limit 1;
RESULT: [duckdb: ERROR, mysql: ERROR]

-----------
QUERY:

explain (costs off) select a, b, a <-> point(5, 5) dist from point_table order by dist, b desc limit 1;
RESULT: [duckdb: ERROR, mysql: ERROR]
=========================================
Summary for test case incremental_sort/test.sql of postgres
=========================================

=================
Results for duckdb
SAME: 34 queries, which is 28.57%
DIFFERENT: 8 queries, which is 6.72%
ERROR: 77 queries, which is 64.71%

=================
Results for mysql
SAME: 12 queries, which is 10.08%
DIFFERENT: 19 queries, which is 15.97%
ERROR: 88 queries, which is 73.95%
